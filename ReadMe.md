# Links to code, dataset, and images for the paper "Do large language vision models understand 3D shapes?"
## Links Code and benchmark for testing Vision Language Models (LVM) ability to identify and match 3D shapes.

![](/Figure1.jpg)


1) The paper ["Do large language vision models understand 3D shapes?"](https://arxiv.org/pdf/2412.10908) can be downloaded from [this URL](https://arxiv.org/pdf/2412.10908).

2) Sample of the dataset are available at: [Zenodo](https://zenodo.org/records/14681299), [Google drive](https://drive.google.com/drive/folders/1pxSnX-qpBfcQ47BbPQmy8pbURk0vXMzu?usp=drive_link), [Pcloud](https://e.pcloud.link/publink/show?code=kZz7FKZ8xfKSIHppBShSuU65cxBvQkorVXV).
   
     Note that, these are just subsamples  of few thousand images, its possible to generate unlimited number of images using the generation script supplied below. 

4) The generation code used to generate the images for the benchmark is available at [this repository](https://github.com/sagieppel/Generate_3D_Shape_Recognition_and_Retrieval_Synthetic_Dataset_Blender).
   
5) Code for evaluating various of LVLMs (GPT, LLama, Gemini, Claude) on the benchmark is available at [this repository](https://github.com/sagieppel/Can-vision-language-models-understand-and-match-3D-shapes/).
