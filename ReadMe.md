# Links to code, dataset, and images for the paper "Do large language vision models understand 3D shapes?"
## Links Code and benchmark for testing Vision Language Models (LVM) ability to identify and match 3D shapes.
![](/Figure1.jpg)


1) The paper ["Do large language vision models understand 3D shapes?"](https://arxiv.org/pdf/2412.10908) can be downloaded from [this URL](https://arxiv.org/pdf/2412.10908).

2) Sample of the dataset can be download from: [Zenodo](https://zenodo.org/records/14681299), [Google drive](https://drive.google.com/drive/folders/1pxSnX-qpBfcQ47BbPQmy8pbURk0vXMzu?usp=drive_link), [Pcloud](https://e.pcloud.link/publink/show?code=kZz7FKZ8xfKSIHppBShSuU65cxBvQkorVXV),  [Icedrive]().
   
     Note that, these are just subsamples  of few thousand images, its possible to generate unlimited number of images using the generation script supplied below. 

4) Generation code use to generate the images for the benchmark available at [this repository](https://github.com/sagieppel/Can-vision-language-models-understand-and-match-3D-shapes/).
   
5) Code for evaluating various of LVLMs (GPT, LLama, Gemini, Claude) on the benchmark available [this repository](https://github.com/sagieppel/Can-vision-language-models-understand-and-match-3D-shapes/).
